<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[obsidian]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.png</url><title>obsidian</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Tue, 08 Oct 2024 18:32:19 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Tue, 08 Oct 2024 18:32:12 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[Implementation]]></title><description><![CDATA[ 
 <br>Early operating systems were written in assembly language. <br>Now, most are written in higher-level languages such as C or C++ with small amounts of the system written in assembly language.<br><br>Code can be written faster, more compact, easier to understand and debug and easier to port to the hardware.<br><br>Reduced speed and increase in storage requirements.]]></description><link>os/cat1/implementation.html</link><guid isPermaLink="false">OS/cat1/Implementation.md</guid><pubDate>Tue, 20 Aug 2024 16:53:39 GMT</pubDate></item><item><title><![CDATA[Mod 1 - Understand Basics of Operating Systems]]></title><description><![CDATA[ 
 <br><br>An operating system (OS) is software that controls hardware and coordinates its use among various application programs and users. It manages computer hardware and provides a platform for running application software.<br><br>The OS acts as a resource manager, overseeing critical resources such as CPU time, memory, storage, and I/O devices. It allocates these resources efficiently and fairly among the running applications to ensure smooth and optimized operation.<br><br><br>
<br>The OS abstracts the complexities of hardware, transforming it into a usable interface for applications. This abstraction simplifies the interaction between software and hardware, allowing developers to create applications without needing to manage hardware details directly.
<br><br>
<br>The OS manages system resources, including memory, processing power, and storage, ensuring that each application gets the necessary resources without conflict. This management is crucial for maintaining system stability and performance.
<br><br>Operating systems provide a range of services that create an environment for the execution of programs. While the specific services can vary between different OS, the core functionalities are generally consistent.<br><br>
<br>Almost all operating systems include a user interface (UI), which could be command-line based, graphical, or a combination of both. The UI allows users to interact with the system and manage applications.
<br><br>
<br>The OS is responsible for loading programs into memory, executing them, and managing their execution lifecycle. It must handle both normal and abnormal terminations, ensuring that resources are released appropriately.
<br><br>
<br>Programs often need to perform I/O operations, such as reading from or writing to files and interacting with I/O devices like printers or network interfaces. The OS provides services to manage these operations efficiently and securely.
<br><br>
<br>The OS manages file systems, enabling programs to create, read, write, delete, and organize files and directories. It also controls access to these files, ensuring data integrity and security.
<br><br>
<br>The OS facilitates communication between processes, whether they are on the same machine or different machines. This is essential for distributed systems and applications that require data exchange between multiple processes.
<br><br>
<br>The OS is constantly aware of potential errors that may occur during operation. It must detect and respond to errors appropriately to prevent system crashes and data loss. This includes handling hardware failures, software bugs, and other unexpected issues.
<br><br><br>
<br>In systems with multiple users or processes running simultaneously, the OS must allocate resources like CPU time, memory, and I/O bandwidth effectively to each process, ensuring optimal performance and fairness.
<br><br>
<br>The OS tracks resource usage for each user or process, which is useful for billing in multi-user systems or for performance monitoring and user analytics.
<br><br>
<br>The OS implements mechanisms to protect the system and its data from unauthorized access. This includes controlling access to resources, protecting data from corruption, and ensuring that only authorized users can perform certain operations.
<br><br>
<br>The OS is responsible for starting, stopping, and managing processes. It schedules processes for execution and allocates necessary resources like CPU time and memory. Process management also includes handling multitasking, where multiple processes run concurrently.
<br><br>
<br>The OS manages the computer's primary memory (RAM), providing mechanisms for allocating memory to processes, swapping data in and out of memory as needed, and ensuring efficient use of available memory.
<br><br>
<br>The OS organizes the file system, managing the creation, deletion, and updating of files and directories. It controls access to files, ensuring that users and applications can only access data they are authorized to use.
<br><br>
<br>The OS manages communication between the system and peripheral devices like printers, displays, keyboards, and storage devices. It ensures that these devices are used efficiently and without conflict.
<br><br>
<br>The OS provides networking capabilities, allowing the computer to communicate with other systems over a network. This includes managing network connections, data transfer, and remote resource access.
<br><br>An operating system is crucial for managing computer hardware and providing a stable environment for applications to run. It abstracts the complexities of hardware, manages system resources, and offers a wide range of services that ensure efficient, secure, and stable operation. Core functionalities include user interfaces, program execution, I/O operations, file management, and communication. Additionally, the OS handles resource allocation, accounting, protection, process management, memory management, and networking, ensuring a comprehensive and robust system.<br>Next: <a data-href="Structuring Operating Systems" href="os/cat1/structuring-operating-systems.html" class="internal-link" target="_self" rel="noopener">Structuring Operating Systems</a>]]></description><link>os/cat1/mod-1-understand-basics-of-operating-systems.html</link><guid isPermaLink="false">OS/cat1/Mod 1 - Understand Basics of Operating Systems.md</guid><pubDate>Sun, 25 Aug 2024 18:31:27 GMT</pubDate></item><item><title><![CDATA[Mod 2 - Processes]]></title><description><![CDATA[ 
 <br>Previous: <a data-href="Module 2 CPU Modes" href="os/cat1/module-2-cpu-modes.html" class="internal-link" target="_self" rel="noopener">Module 2 CPU Modes</a><br><br>In an operating system, each process has its own virtual address space, which is separate from other processes. This virtual space is divided into distinct regions:<br><img alt="Compiler Design/Pasted image 20240826120353.png" src="lib/media/pasted-image-20240826120353.png"><br>
<br>Text Segment: Contains the executable code of the program.
<br>Data Segment: Stores global and static variables.
<br>Heap: Used for dynamic memory allocation during process execution.
<br>Stack: Holds the activation records for functions, including function parameters, local variables, and return addresses.
<br><br>
<br>Each time a function is called, an activation record (or stack frame) is pushed onto the stack.
<br>This record contains:

<br>Function parameters
<br>Local variables
<br>Return address


<br>When the function returns, its activation record is popped from the stack.
<br>The stack and heap sections grow toward each other, and the operating system must ensure they do not overlap.<br><br>
<br>The MMU translates the virtual addresses used by the process into physical memory addresses.
<br><br>As a process executes, it changes state, which is defined by the current activity of that process. A process may be in one of the following states:<br>
<br>New: The process is being created.
<br>Running: Instructions are being executed.
<br>Waiting: The process is waiting for some event (like I/O completion) to occur.
<br>Ready: The process is waiting to be assigned to a processor.
<br>Terminated: The process has finished execution.
<br><br>The Process Control Block (PCB), also known as a task control block, is a data structure that contains all the information about a process. The PCB acts as the handle for the OS to manage the process's memory layout, scheduling, and other resources.<br><br>
<br>Process State: New, ready, running, waiting, or terminated.
<br>Program Counter: The address of the next instruction to be executed.
<br>CPU Registers: Includes accumulators, index registers, stack pointers, general-purpose registers, and condition codes.
<br>CPU-Scheduling Information: Includes process priority, pointers to scheduling queues, and other scheduling parameters.
<br>Memory-Management Information: Includes base and limit registers, page tables, or segment tables, depending on the memory system.
<br>Accounting Information: Includes CPU usage, time limits, account numbers, and process IDs.
<br>I/O Status Information: Includes the list of I/O devices allocated to the process and the list of open files.
<br><br>The Process Table is a data structure maintained by the operating system to store information about all active processes. It is essentially an array of PCBs, with each entry representing a process and containing a pointer to its corresponding PCB.<br><br>Processes are created in an operating system using system calls. The process that creates new processes is called the parent process, and the newly created processes are called child processes.<br><br>
<br>Each process is identified by a unique Process Identifier (PID), which is typically an integer.
<br>The PID is used to access various attributes of a process within the kernel.
<br><br>
<br>fork(): Creates a new process (child) that is a copy of the current process (parent). The child starts executing from the point where fork() was called.
<br>wait(): Suspends the parent process until one of its child processes terminates. The exit status of the child process is stored in the wstatus parameter.
<br>exec(): Replaces the child process image with a new program loaded from a specified file.
<br>exit(): Terminates the current process and returns a status code to the parent, which can use this code to determine the reason for termination.
<br><br>A process terminates when it finishes executing its final statement and requests the OS to delete it using the exit() system call. All the resources of the process are deallocated and reclaimed by the operating system.<br><br>
<br>A parent process can terminate its children for reasons like:

<br>Exceeding resource usage.
<br>Task completion.
<br>Parent process exiting.


<br><br>
<br>If a parent process terminates, all its child processes must also be terminated.
<br><br>
<br>A parent process can wait for a child process to terminate using the wait() system call. The parent can retrieve the exit status of the child and free up the process table entry.
<br><br><br>
<br>A zombie process is a process that has finished execution, but its parent has not yet acknowledged its termination.
<br>The zombie process still exists in the process table, awaiting the parent to retrieve its exit status using wait().
<br>It remains in the process table until the parent terminates or the system reboots.
<br><br>
<br>An orphan process is a process whose parent has terminated, but the child is still running.
<br>The orphan process is adopted by the init process (PID 1), which becomes its new parent.
<br>The init process periodically invokes wait(), allowing it to clean up and release the resources of orphaned processes.
]]></description><link>os/cat1/mod-2-processes.html</link><guid isPermaLink="false">OS/cat1/Mod 2 - Processes.md</guid><pubDate>Wed, 28 Aug 2024 16:14:07 GMT</pubDate><enclosure url="lib/media/pasted-image-20240826120353.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="lib/media/pasted-image-20240826120353.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Module 2 - System Calls]]></title><description><![CDATA[ 
 <br><br><br>System calls provide an interface for user programs to interact with the operating system (OS). These calls are essentially functions written in languages like C and C++ that act as a bridge between the OS and a running process. They allow user-level programs to request services from the OS, such as file operations, process control, and memory management.<br>When a computer program needs to access the OS's kernel services, it makes a system call, which uses an API to expose these services to user programs. System calls are the only method for accessing the kernel system directly, ensuring controlled and secure interaction with the OS.<br><br>Consider a scenario where a user program needs to read data from a file. The program issues a read system call to request the OS to retrieve the data. The system call transitions the program from user mode to kernel mode, where the OS performs the necessary file operations. Once the data is read, control returns to the user mode, along with the required data.<br><br>An API defines a set of functions that application developers can use to request services from the OS or other applications. It specifies the parameters required, the expected return values, and the correct way to request these services. The API serves as a higher-level abstraction over system calls, making it easier for developers to interact with the OS.<br><br>
<br>Portability: Programs designed using an API can run on any system that supports the same API, ensuring cross-platform compatibility.
<br>Simplified Interaction: APIs often abstract the complexity of system calls, providing a more user-friendly interface for developers.
<br><br>Consider the POSIX API, which is widely used in Unix-like operating systems. A developer writing a program that needs to create a new process might use the fork() function, which is defined by the POSIX API. This function internally makes a system call to the kernel to create the process but simplifies the interaction for the developer.<br><br>System calls are implemented within the OS kernel and are accessed through a system-call interface. This interface acts as a link between user programs and the system calls, with each call associated with a unique number. The system-call interface maintains a table indexed by these numbers, allowing the correct system call to be invoked based on the user's request.<br>When a system call is made, the interface invokes the intended call in the kernel and returns the status of the operation. The user program does not need to know the details of how the system call is implemented; it only needs to follow the API and understand the expected behavior.<br><br>There are three general methods for passing parameters to the OS when making a system call:<br>
<br>Registers: The simplest method is to pass parameters directly in registers.
<br>Memory Block: Parameters can be stored in a block or table in memory, with the address of the block passed in a register.
<br>Stack: Parameters can be pushed onto the stack by the program and then popped off by the OS.
<br><br>When reading a file, the address of the buffer where the data should be stored might be passed to the OS using one of these methods. For instance, in the case of a memory block, the address of the block holding the file's metadata could be passed to the kernel, which then processes the read operation.<br><br>System calls are essential for enabling user programs to interact with the OS, providing services such as file operations, process management, and more. They are accessed through an API, which abstracts the complexity and ensures cross-platform compatibility. System calls are implemented within the kernel and accessed via a system-call interface, which manages the parameters and invokes the appropriate kernel functions. By using APIs, developers can design programs that are portable and easier to manage, without needing to understand the underlying system call details.<br>// System call types ?????<br>Next: <a data-href="Module 2 CPU Modes" href="os/cat1/module-2-cpu-modes.html" class="internal-link" target="_self" rel="noopener">Module 2 CPU Modes</a>]]></description><link>os/cat1/module-2-system-calls.html</link><guid isPermaLink="false">OS/cat1/Module 2 - System Calls.md</guid><pubDate>Sun, 25 Aug 2024 19:35:42 GMT</pubDate></item><item><title><![CDATA[Module 2 - Threads]]></title><description><![CDATA[ 
 <br><br>A thread is a basic unit of CPU utilization within a process, representing a single sequential flow of execution. It includes a thread ID, a program counter, a register set, and a stack. Threads are considered lightweight processes because they share resources and are faster compared to traditional processes.<br><br>
<br>Lightweight: Threads are lighter than processes, requiring fewer resources.
<br>Shared Resources: Threads within the same process share the same code, data, and file descriptors.
<br>Fast Context Switching: Switching between threads is quicker than switching between processes because threads share the same memory space.
<br>Concurrent Execution: Threads can run concurrently, enhancing system performance and responsiveness by performing multiple tasks simultaneously.
<br><br>A single-threaded process contains only one thread, which executes tasks sequentially. This type of process has its own memory space and does not support concurrent execution.<br>Characteristics of Single-Threaded Processes:<br>
<br>Only One Thread: At any given time, only one thread runs.
<br>No Shared Memory Space: Each process has its own memory space.
<br>No Synchronization Needed: Since there is only one thread, synchronization mechanisms are not required.
<br>Easier Implementation and Debugging: Single-threaded processes are simpler to implement and debug due to their straightforward execution model.
<br>Advantages of Single-Threaded Processes:<br>
<br>Simplicity: Easier to implement and debug, with less complexity in managing execution.
<br>Lower Overhead: Consumes less memory and system resources compared to multithreaded processes.
<br>Ease of Understanding: Straightforward to understand and maintain due to lack of concurrency issues.
<br><br>Multithreading involves multiple threads running within a single process, allowing for concurrent execution and efficient resource utilization.<br><br>
<br>Kernel Multithreading: Most operating system kernels are multithreaded, where each kernel thread manages specific tasks like device management, interrupt handling, or memory management.

<br>Example: In Linux, the command ps -ef displays kernel threads, including kthreadd (PID = 2), which is the parent of all kernel threads.


<br><br>
<br>Improved Responsiveness: Multithreading allows applications to remain responsive by performing background tasks while the user interacts with the UI.
<br>Increased Throughput: Enables multiple threads to run simultaneously, enhancing the overall throughput of the system.
<br>Better Resource Utilization: Makes efficient use of CPU resources, especially when some threads are waiting for I/O operations.
<br>Simplified Concurrent Programming: Facilitates the implementation of programs that need to perform multiple tasks concurrently, such as handling multiple client requests.
<br><br>Multithreading models describe the relationship between user threads and kernel threads. They determine how user-level threads are mapped to kernel threads.<br>
<br>
Many-to-One Model:

<br>Description: Multiple user threads are mapped to a single kernel thread. Thread management is done in user space.
<br>Advantages: Simplicity in implementation with minimal overhead.
<br>Disadvantages: A blocking system call by one thread blocks the entire process. This model does not utilize multi-core processors efficiently.
<br>Example: Early Java Green Threads used this model.


<br>
One-to-One Model:

<br>Description: Each user thread is mapped to a single kernel thread. This model allows better concurrency.
<br>Advantages: Multiple threads can run in parallel on multi-core processors. Blocking calls in one thread do not affect others.
<br>Disadvantages: Creating user threads requires creating corresponding kernel threads, which can burden system performance.
<br>Example: Modern Windows and Linux operating systems use this model but with restrictions to limit performance impact.


<br>
Many-to-Many Model:

<br>Description: Multiple user threads are mapped to a smaller or equal number of kernel threads. This model allows better flexibility and resource utilization.
<br>Advantages: Provides better concurrency and efficient resource usage. Allows kernel to schedule another thread if one is blocked.
<br>Disadvantages: Complex to implement and manage, particularly in mapping user and kernel threads.
<br>Example: Solaris uses a variation of this model.


<br>
Two-Level Model:

<br>Description: Combines many-to-one and one-to-one models. It supports user-level and kernel-level threads.
<br>Advantages: Balances concurrency and resource utilization. Effectively handles blocking system calls and utilizes multiprocessor systems.
<br>Disadvantages: More complex than single-level models, requiring careful implementation to avoid inefficiencies.
<br>Example: Some versions of IRIX and HP-UX use this model.


<br><br>
<br>Threads are lightweight, share resources, and provide efficient context switching compared to processes.
<br>Single-threaded processes are simpler but do not support concurrent execution.
<br>Multithreading improves responsiveness, throughput, and resource utilization, with various models offering different trade-offs in complexity and performance.
<br>Understanding these concepts is crucial for designing effective and efficient applications and systems.
]]></description><link>os/cat1/module-2-threads.html</link><guid isPermaLink="false">OS/cat1/Module 2 - Threads.md</guid><pubDate>Sun, 25 Aug 2024 18:53:09 GMT</pubDate></item><item><title><![CDATA[Module 2 CPU Modes]]></title><description><![CDATA[ 
 <br><br>Previous : <a data-href="Module 2 - System Calls" href="os/cat1/module-2-system-calls.html" class="internal-link" target="_self" rel="noopener">Module 2 - System Calls</a><br>The CPU operates in two distinct modes, User Mode and Kernel Mode, to ensure system stability and security.<br><br>
<br>Restricted Access: User mode is a restricted mode that limits a program's access to system resources. Programs running in this mode cannot directly interact with hardware or memory; instead, they must use system calls to request these services from the operating system (OS).
<br>Process Isolation: When a user-mode application starts, the OS creates a process for it. This process is provided with:

<br>Private Virtual Address Space: Each application gets its own virtual address space, ensuring that one application cannot alter the data of another. This isolation protects the system from cascading failures—if one application crashes, it does not affect others.
<br>Private Handle Table: Applications manage resources (like files or network connections) through a private handle table.


<br>Instruction Restrictions: If an application in user mode attempts to execute a privileged instruction (one that can alter system behavior), the hardware treats this as illegal and does not execute it.
<br><br>When you open a text editor on Windows, it runs in user mode. If it crashes, only the text editor is affected, and the rest of the system continues to operate normally.<br><br>
<br>Privileged Access: Kernel mode is a privileged mode where the executing code has unrestricted access to all system resources, including hardware and memory.
<br>Complete Control: The code running in kernel mode can execute any CPU instruction and access any memory address.
<br>Shared Virtual Address Space: All code in kernel mode shares a single virtual address space. This lack of isolation means that if a driver or the OS itself writes to the wrong memory address, it can corrupt data across the entire system, potentially causing a system-wide crash.
<br><br>At system startup, the OS loads in kernel mode. Any system drivers or core components of the OS that run in kernel mode have the ability to interact directly with the hardware.<br><br>
<br>System Boot: The system begins in kernel mode when the OS is loaded. Once the OS is running, user applications start in user mode.
<br>Mode Switching: The CPU switches from user mode to kernel mode whenever a system call, trap, or interrupt occurs. This switch allows the OS to safely handle the requested operations.
<br>Protection: This dual-mode operation protects the OS and system resources from errant or malicious user programs, ensuring the stability and security of the system.
<br><br>Interrupts are signals that allow the OS to temporarily halt its current operations and execute specific functions, known as Interrupt Service Routines (ISRs).<br><br>
<br>Interrupt Request: A hardware device sends an interrupt request to the CPU.
<br>Acknowledgment: The CPU acknowledges the request and temporarily halts its current execution.
<br>Interrupt Vector: The CPU uses the interrupt vector, a table of pointers to ISRs, to locate the appropriate handler for the interrupt.
<br>Interrupt Service Routine: The CPU executes the ISR to handle the interrupt, which might involve reading data from a device, processing input, or handling an error.
<br>Resume Execution: After the ISR completes, the CPU resumes its previous activity from where it was interrupted.
<br><br>
<br>The CPU has a wire called the Interrupt-Request Line that it checks after executing each instruction. If an interrupt is detected, the CPU reads the interrupt number and jumps to the corresponding ISR using the interrupt vector. The ISR then saves the current state, processes the interrupt, and returns control to the CPU, allowing it to resume its previous task.
<br><br>
<br>Deferred Handling: Modern interrupt handlers can defer certain operations until critical processing is complete, improving system efficiency.
<br>Efficient Dispatching: These handlers can quickly identify and dispatch the correct ISR for a device.
<br>Multilevel Interrupt Handling: Modern systems distinguish between high and low-priority interrupts, allowing the CPU to respond with the appropriate urgency.
<br><br>
<br>Maskable Interrupts: These interrupts can be ignored or disabled by the CPU, giving the system flexibility in handling less critical events.
<br>Non-Maskable Interrupts (NMI): These interrupts cannot be ignored or disabled by the CPU and are reserved for critical situations that require immediate attention.
<br><br>The CPU operates in two modes—user mode and kernel mode—to manage and protect system resources. User mode restricts access to hardware and memory, ensuring process isolation, while kernel mode allows unrestricted access to system resources. Interrupts are critical signals that enable the OS to respond to hardware events in real time, with modern interrupt handlers designed for efficiency and prioritization. The dual-mode operation and interrupt handling mechanisms together ensure that the OS maintains control, stability, and security across all system operations.<br>next: <a data-href="Mod 2 - Processes" href="os/cat1/mod-2-processes.html" class="internal-link" target="_self" rel="noopener">Mod 2 - Processes</a>]]></description><link>os/cat1/module-2-cpu-modes.html</link><guid isPermaLink="false">OS/cat1/Module 2 CPU Modes.md</guid><pubDate>Mon, 26 Aug 2024 07:43:29 GMT</pubDate></item><item><title><![CDATA[OS Design]]></title><description><![CDATA[ 
 <br>Previous: <a data-href="Structuring Operating Systems" href="os/cat1/structuring-operating-systems.html" class="internal-link" target="_self" rel="noopener">Structuring Operating Systems</a><br><br>
<br>Start the design by defining goals and specifications
<br>Choice of hardware
<br>System types
<br>Specify the requirements

<br>user goals
<br>System goals


<br><a data-href="Separation of policy from mechanism" href="os/cat1/separation-of-policy-from-mechanism.html" class="internal-link" target="_self" rel="noopener">Separation of policy from mechanism</a>
<br><a data-href="Implementation" href="os/cat1/implementation.html" class="internal-link" target="_self" rel="noopener">Implementation</a>
]]></description><link>os/cat1/os-design.html</link><guid isPermaLink="false">OS/cat1/OS Design.md</guid><pubDate>Sun, 25 Aug 2024 12:31:05 GMT</pubDate></item><item><title><![CDATA[Separation of policy from mechanism]]></title><description><![CDATA[ 
 <br>Mechanism determines how to do something, policies decide what will be done.<br>
Separation of policy and mechanism is important for flexibility.<br>
Policies change with time, with each change in policy likely requires change in the underlying mechanism.<br>
Policy decisions are important for all resource allocation.]]></description><link>os/cat1/separation-of-policy-from-mechanism.html</link><guid isPermaLink="false">OS/cat1/Separation of policy from mechanism.md</guid><pubDate>Tue, 20 Aug 2024 16:51:10 GMT</pubDate></item><item><title><![CDATA[Structuring Operating Systems]]></title><description><![CDATA[ 
 <br> Previous : <a data-href="Mod 1 - Understand Basics of Operating Systems" href="os/cat1/mod-1-understand-basics-of-operating-systems.html" class="internal-link" target="_self" rel="noopener">Mod 1 - Understand Basics of Operating Systems</a><br><br><br>The kernel is the core component of an operating system, responsible for managing system resources and providing low-level services to other components. It operates in a privileged mode known as kernel mode, giving it direct access to hardware and system resources.<br>
<br>Responsibilities:

<br>Memory Management: Oversees the allocation and deallocation of memory to processes, ensuring that each process operates within its allocated space and preventing unauthorized access.
<br>CPU Time Management: Allocates CPU time to various processes, ensuring efficient process scheduling and multitasking. This involves managing process states and transitions between running, ready, and waiting states.
<br>Disk Management: Manages data storage and retrieval from disk drives, including handling file systems and data caching to improve performance.
<br>Task Management: Handles process creation, execution, and termination, including context switching between processes to ensure smooth multitasking.


<br><br>
<br>Role: Manages the allocation of CPU time among processes, ensuring that system resources are used efficiently.
<br>Function: Determines which processes run at any given time based on scheduling algorithms. It prioritizes processes and manages their execution to optimize system performance.
<br>Examples of Scheduling Algorithms:

<br>Round Robin: Each process is assigned a fixed time slice in a cyclic order. Example: Unix-like systems.
<br>Priority Scheduling: Processes are prioritized based on predefined criteria, and higher-priority processes are given more CPU time. Example: Windows.


<br><br>
<br>Role: Manages memory allocation and deallocation, ensuring efficient use of system memory and preventing conflicts between processes.
<br>Function: Handles memory allocation for processes, implements paging and swapping techniques to manage memory resources, and ensures that processes do not interfere with each other's memory spaces.
<br>Examples:

<br>Paging: Divides memory into fixed-size pages and maps them to physical memory. Example: Linux.
<br>Swapping: Moves processes between physical memory and disk storage to manage memory pressure. Example: Windows.


<br><br>
<br>Role: Organizes and manages storage on secondary devices like hard disks, ensuring data is stored and retrieved efficiently.
<br>Function: Handles file creation, deletion, modification, and access. Manages directories, file permissions, and ensures data integrity and security.
<br>Examples of File Systems:

<br>NTFS: Used by Windows for its advanced features and security. Example: Windows.
<br>EXT4: Commonly used by Linux for its reliability and performance. Example: Linux.
<br>APFS: Used by macOS for its advanced features like encryption and snapshots. Example: macOS.


<br><br>
<br>Role: Serve as the interface between the operating system and hardware devices, providing the necessary commands and protocols to interact with devices.
<br>Function: Translate OS-level commands into device-specific operations and manage communication between the hardware and software.
<br>Examples of Device Drivers:

<br>Printer Drivers: Manage printing operations. Example: HP LaserJet drivers for Windows.
<br>Network Drivers: Handle network communication. Example: Intel network drivers for Linux.


<br><br>
<br>Role: Provides a means for users to interact with the operating system, facilitating program launches, file management, and system tasks.
<br>Function: Offers different modes of interaction, including command-line interfaces (CLI), graphical user interfaces (GUI), or a combination of both.
<br>Examples:

<br>CLI: Allows users to interact with the OS using text commands. Example: Terminal in Linux.
<br>GUI: Provides a visual interface with windows, icons, and menus. Example: Windows Desktop Environment.


<br><br>
<br>Definition: Interfaces provided by the operating system for programs to request services from the kernel.
<br>Function: Allows user-level processes to perform operations such as file management, process control, and communication with hardware.
<br>Examples of System Calls:

<br>open(): Opens a file. Example: Unix-based systems.
<br>read(): Reads data from a file. Example: Unix-based systems.
<br>write(): Writes data to a file. Example: Unix-based systems.
<br>close(): Closes an open file descriptor. Example: Unix-based systems.


<br><br><br>
<br>Description: All system services run in kernel space without separation between kernel and user processes. This approach integrates various functionalities into a single large kernel.
<br>Components: Includes file system management, memory management, process management, and device drivers.
<br>Advantages:

<br>Simplicity: Easy to implement with fewer components.
<br>Performance: Direct system calls lead to high performance and low overhead.


<br>Disadvantages:

<br>Security: Vulnerabilities in the kernel affect the entire system, reducing security and stability.
<br>Flexibility: Less modularity and difficulty in maintaining or extending the kernel.


<br>Examples: Early versions of Unix, small embedded systems.
<br><br>
<br>Description: Divides the OS into layers, each responsible for specific functions. Each layer interacts only with the layer directly below it.
<br>Components: Hardware layer at the bottom, user interface at the top, with intermediate layers handling system services.
<br>Advantages:

<br>Modularity: Simplifies maintenance and debugging due to well-defined layers.
<br>Isolation: Changes in one layer do not affect others, enhancing system stability.


<br>Disadvantages:

<br>Performance Overhead: Layered interactions may introduce performance overhead.
<br>Complexity: Managing and defining layer functionality can be complex.


<br>Examples: OS/2, some modern implementations of Linux.
<br><br>
<br>Description: Minimizes the kernel's responsibilities, moving most services to user space. The microkernel handles only essential functions such as communication and basic resource management.
<br>Components: Includes a small microkernel for fundamental tasks and user-space services for other functionalities.
<br>Advantages:

<br>Extensibility: Easier to extend and port to different hardware.
<br>Security and Stability: Improved security and stability due to most services running in user space.


<br>Disadvantages:

<br>Performance Overhead: Increased messaging and context switching between user and kernel space can impact performance.
<br>Complexity: Managing communication between kernel and user-space services adds complexity.


<br>Examples: Mach microkernel used in NeXTSTEP and macOS, MINIX operating system.
<br><br>Overview: LKMs allow the kernel to be extended dynamically without recompilation. These modules can be loaded and unloaded at runtime, providing flexibility and adaptability.<br>Key Features:<br>
<br>Modularity: Core functionalities are maintained while additional features are added or removed dynamically.
<br>Dynamic Loading: Supports the introduction of new services like device drivers or file systems without rebooting.
<br>Resource Management: Unloads modules when no longer needed to free system resources.
<br>Communication: Simplifies interaction with the kernel without message passing.
<br>Advantages:<br>
<br>Flexibility: Adapts to changing requirements and hardware without requiring system restarts or recompilation.
<br>Reduced Overhead: Avoids the need for frequent kernel recompilation, saving time and resources.
<br>Efficient Resource Utilization: Enables on-demand loading and unloading of functionalities.
<br>Examples of Operating Systems Using LKMs:<br>
<br>Linux: Implements a modular approach for hardware support and system services.
<br>Solaris: Uses dynamic loading for modular extensions.
<br>macOS and Windows: Incorporate modules to enhance kernel functionalities.
<br><br>Overview: Hybrid operating systems blend multiple kernel architectures to leverage their combined strengths, aiming to balance performance, security, and usability.<br>Hybrid System Examples:<br>
<br>Linux: Primarily monolithic but supports modular components for dynamic functionality.
<br>Windows: Monolithic core with microkernel elements for subsystem functionalities.
<br>macOS: Combines Mach microkernel with BSD UNIX kernel components.
<br><br>Architecture: Both are built on Darwin, which integrates Mach microkernel and BSD UNIX elements. They feature layered architectures:<br>
<br>
User Experience Layer:

<br>macOS: Aqua
<br>iOS: Springboard


<br>
Application Framework Layer:

<br>macOS: Cocoa
<br>iOS: Cocoa Touch


<br>
Core Frameworks:

<br>Support graphics and media, such as QuickTime and OpenGL.


<br>
Kernel:

<br>Darwin: Combines Mach microkernel and BSD UNIX elements.


<br>Distinctions:<br>
<br>Architecture:

<br>macOS: Designed for Intel architectures.
<br>iOS: Compiled for ARM-based architectures.


<br>Developer Restrictions:

<br>macOS: Offers open access to POSIX and BSD APIs.
<br>iOS: Enforces restrictions to ensure security and control.


<br>System Calls:<br>
<br>Mach System Calls: Core services for memory management and CPU scheduling.
<br>BSD System Calls: Support networking, security, and programming languages.
<br>Next: <a data-href="OS Design" href="os/cat1/os-design.html" class="internal-link" target="_self" rel="noopener">OS Design</a>]]></description><link>os/cat1/structuring-operating-systems.html</link><guid isPermaLink="false">OS/cat1/Structuring Operating Systems.md</guid><pubDate>Sun, 25 Aug 2024 19:04:00 GMT</pubDate></item><item><title><![CDATA[Deadlocks]]></title><description><![CDATA[ 
 <br><br><br><br><br>
<br>Situation where two or more processes are unable to proceed because each is waiting for a resource that is held by another process in the same set of processes
<br><br>
<br>Formal representation of the resources and processes involved in a deadlock situation
<br>Helps in understanding the conditions and interactions that can lead to a deadlock
<br><br><br>
<br>Preemptable Resources: These resources can be taken away from a process without causing any adverse effects. Ex: memory, CPU cycles and I/O devices
<br>Non-preemptable Resources: Cannot be taken away from a process once they have been allocated. Ex: Printers, CD drives, specialized hardware
<br><br>Executing units in an operating system. Processes can request and release resources during their execution<br>
Each process has a set of activities or tasks that need to be completed<br>
Processes or Thread may utilize a resource in only the following sequence:<br>
<br>Request: The thread requests the resource. If the request can't be granted immediately, then the requesting thread must wait until it can acquire the resource.
<br>Use: The thread can operate on the resource
<br>Release: The thread releases the resources
<br><br>Four necessary conditions for deadlock to occur: <br>
<br>Mutual Exclusion - Once a process acquires a resource, other processes are denied access to it until the resource is released
<br>Hold and Wait - Processes hold resources while waiting for additional resources. This means that a process may be holding one or more resources and is also waiting to acquire additional resources that are currently being held by other processes
<br>No Preemption - Resources can't be forcibly taken away from a process. They can only be released voluntarily by the process holding them 
<br>Circular Wait - There exists a circular chain of two or more processes , where each process is waiting for a resource that is held by another process in the chain. In other words, the last process in the chain is waiting for a resource held by the first process, creating a circular dependency
<br><img alt="Pasted image 20241008215242.png" src="os/cat2/pasted-image-20241008215242.png"><br><br><br>
<br>When the four conditions are satisfied, a deadlock can occur. As a result, none of the processes involved can make progress, leading to a system deadlock
<br>Dealing: 

<br>We can ignore the problem altogether and pretend that deadlocks never occur in the system
<br>We can use a protocol to prevent or avoid deadlocks, ensuring that the system will never enter a deadlocked state
<br>We can allow the system to enter a deadlocked state, detect it and recover
<br>Techniques:

<br>Resource allocation strategies
<br>Deadlock detection algorithms
<br>Deadlock recovery mechanism


<br>Goal - to ensure that the system remains in a safe state where deadlocks cannot occur or if they do occur, they can be resolved efficiently to restore system functionality


<br><br>
<br>Ensure that any one condition - Mutual Exclusion, No preemption, Hold and Wait, Circular Wait does not hold. Then occurrences of the Deadlock can be prevented
<br>It is a proactive approach
<br>It aims to identify and eliminate the conditions that lead to deadlocks by enforcing restrictions on resource allocation  and process execution
<br><br>
<br>Ensure that resources are shareable whenever possible
<br>If multiple processes can access a resource simultaneously without interfering with each other's operations, the issue of mutual exclusion is eliminated
<br>For resources that can't be shares, consider allowing multiple processes to have read-only access while enforcing exclusive access for write operations
<br><br>
<br>Implement a strategy where:

<br>Processes must require and acquire all the necessary resources they need before starting execution. This can be achieved by using "all or nothing" or "claim all" strategy
<br>Another protocol allows a thread to request resources only when it has none. Before it can request any additional resources, it must release all the resources


<br>Disadvantages: Resource utilization may be low, starvation is possible <br><img alt="Pasted image 20241008220841.png" src="os/cat2/pasted-image-20241008220841.png"><br><img alt="Pasted image 20241008220901.png" src="os/cat2/pasted-image-20241008220901.png"><br><img alt="Pasted image 20241008220917.png" src="os/cat2/pasted-image-20241008220917.png"><br><br>//Deadlock 2<br><br>
<br>Deadlock prevention algorithms prevent deadlocks by limiting how requests can be made
<br>The limits ensure that at least one of the necessary conditions for deadlock can't occur
<br>Side effects - low device utilization and reduced system throughput
<br><br><br>
<br>
An algorithm that examines the state of the system to determine whether a deadlock has occurred

<br>
If all resources have only a single instance, then we can define a deadlock detection algorithm that uses a variant of the resource-allocation graph called a wait-for graph

<br>
A deadlock exists in the system if and only if the wait-for graph contains a cycle

<br>
To detect deadlocks, the system needs to maintain the wait for graph and periodically invoke an algorithm that searches for a cycle in the graph -&gt; Time complexity O() operations( n - number of vertices in the graph)

]]></description><link>os/cat2/deadlocks.html</link><guid isPermaLink="false">OS/cat2/Deadlocks.md</guid><pubDate>Tue, 08 Oct 2024 18:28:35 GMT</pubDate><enclosure url="os/cat2/pasted-image-20241008215242.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="os/cat2/pasted-image-20241008215242.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Hello CAT-2]]></title><description><![CDATA[ 
 <br><img alt="Pasted image 20241007233700.png" src="os/cat2/pasted-image-20241007233700.png"><br><img alt="Pasted image 20241007233719.png" src="os/cat2/pasted-image-20241007233719.png"><br><a data-href="Deadlocks" href="os/cat2/deadlocks.html" class="internal-link" target="_self" rel="noopener">Deadlocks</a><br>Kumaresan<br>
Narayanan Prashanth]]></description><link>os/cat2/hello-cat-2.html</link><guid isPermaLink="false">OS/cat2/Hello CAT-2.md</guid><pubDate>Mon, 07 Oct 2024 18:22:20 GMT</pubDate><enclosure url="os/cat2/pasted-image-20241007233700.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="os/cat2/pasted-image-20241007233700.png"&gt;&lt;/figure&gt;</content:encoded></item></channel></rss>